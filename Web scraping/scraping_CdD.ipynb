{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Raspagem de dados do site da Câmara dos deputados\n",
    "<p> Web scraper do site da Câmara dos deputados(CdB) utilizando a biblioteca selenium para scraping, pandas para formatação e time para testes temporizados. A iniciativa nasceu da dificuldade de baixar chaves de pesquisas com muitas proposições, o site do CdB limita que somente 1500 informações de proposições pudessem ser baixadas, então o scraper possibilitou que todas as informações fossem coletadas sem limitações. A coleta dos dados deste projeto foi feita no dia 24/01/2021.</p>\n",
    "<p> O HTML do site foi analisado e utilizado para automatizar o maior número de processos possíveis. O Código preenche a pesquisa avançada automaticamente, checa quantas informações precisam ser baixadas e descobre a partir do número de proposições por página quando precisa parar de rodar. No fim salva todas informações coletadas em um arquivo excel</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa bibliotecas\n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Informações da pesquisa avançada\n",
    "\n",
    "# Chaves de pesquisa\n",
    "chaves = ['Saúde pública','Sistema Único de Saúde']\n",
    "\n",
    "# Janela de datas de apresentação a se procurar\n",
    "data_inicial = '01012010'\n",
    "data_final = '01072020'\n",
    "\n",
    "# Botões a se apertar no site (PLP, PEC e PL)\n",
    "botoes = ['PLP\\ \\ \\ \\ \\ \\ \\ \\ -\\ Projeto\\ de\\ Lei\\ Complementar',\n",
    "          'PEC\\ \\ \\ \\ \\ \\ \\ \\ -\\ Proposta\\ de\\ Emenda\\ à\\ Constituição',\n",
    "          'PL\\ \\ \\ \\ \\ \\ \\ \\ \\ -\\ Projeto\\ de\\ Lei']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raspando informações - Chave: Saúde pública"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "40\n",
      "60\n",
      "80\n",
      "100\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "120\n",
      "140\n",
      "160\n",
      "180\n",
      "200\n",
      "220\n",
      "240\n",
      "260\n",
      "280\n",
      "280\n",
      "280\n",
      "280\n",
      "280\n",
      "300\n",
      "320\n",
      "340\n",
      "360\n",
      "380\n",
      "400\n",
      "420\n",
      "440\n",
      "460\n",
      "480\n",
      "500\n",
      "520\n",
      "540\n",
      "560\n",
      "580\n",
      "600\n",
      "620\n",
      "640\n",
      "660\n",
      "680\n",
      "680\n",
      "680\n",
      "700\n",
      "720\n",
      "740\n",
      "760\n",
      "780\n",
      "800\n",
      "820\n",
      "840\n",
      "860\n",
      "880\n",
      "900\n",
      "920\n",
      "940\n",
      "960\n",
      "980\n",
      "1000\n",
      "1020\n",
      "1040\n",
      "1060\n",
      "1080\n",
      "1100\n",
      "1120\n",
      "1140\n",
      "1160\n",
      "1180\n",
      "1200\n",
      "1220\n",
      "1240\n",
      "1260\n",
      "1280\n",
      "1300\n",
      "1320\n",
      "1340\n",
      "1360\n",
      "1380\n",
      "1400\n",
      "1420\n",
      "1440\n",
      "1460\n",
      "1480\n",
      "1500\n",
      "1520\n",
      "1540\n",
      "1560\n",
      "1580\n",
      "1600\n",
      "1620\n",
      "1640\n",
      "1660\n",
      "1680\n",
      "1700\n",
      "1720\n",
      "1740\n",
      "1760\n",
      "1780\n",
      "1800\n",
      "1820\n",
      "1840\n",
      "1860\n",
      "1880\n",
      "1900\n",
      "1920\n",
      "1940\n",
      "1960\n",
      "1980\n",
      "2000\n",
      "2020\n",
      "2040\n",
      "2060\n",
      "2080\n",
      "2100\n",
      "2120\n",
      "2140\n",
      "2160\n",
      "2180\n",
      "2200\n",
      "2220\n",
      "2240\n",
      "2260\n",
      "2280\n",
      "2300\n",
      "2320\n",
      "2340\n",
      "2360\n",
      "2380\n",
      "2400\n",
      "2420\n",
      "2440\n",
      "2460\n",
      "2480\n",
      "2500\n",
      "2520\n",
      "2540\n",
      "2560\n",
      "2580\n",
      "2600\n",
      "2620\n",
      "2640\n",
      "2660\n",
      "2680\n",
      "2700\n",
      "2720\n",
      "2740\n",
      "2760\n",
      "2780\n",
      "2800\n",
      "2820\n",
      "2840\n",
      "2860\n",
      "2880\n",
      "2900\n",
      "2920\n",
      "2940\n",
      "2960\n",
      "2980\n",
      "3000\n",
      "3020\n",
      "3040\n",
      "3060\n",
      "3080\n",
      "3100\n",
      "3120\n",
      "3140\n",
      "3160\n",
      "3180\n",
      "3200\n",
      "3220\n",
      "3240\n",
      "3260\n",
      "3280\n",
      "3300\n",
      "3320\n",
      "3340\n",
      "3360\n",
      "3380\n",
      "3394\n"
     ]
    }
   ],
   "source": [
    "# Abre o google crhome\n",
    "driver = webdriver.Chrome()\n",
    "try:\n",
    "    driver.get('https://www.camara.leg.br/buscaProposicoesWeb/pesquisaAvancada')\n",
    "    ## ------ início pesquisa avançada ------------\n",
    "    # Aperta oos botões baseado no ID deles\n",
    "    for bot in botoes:\n",
    "        botao = driver.find_element_by_id(bot)\n",
    "        botao.click()\n",
    "    # Seleciona a checkbox sim para Em Tramitação\n",
    "    is_tram_yes = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div/div/div/div[2]/div/div/div/div/form/fieldset[2]/fieldset/ul/li[2]/input')\n",
    "    is_tram_yes.click()\n",
    "    \n",
    "    #time.sleep(2)\n",
    "    # Encontra os campos de datas\n",
    "    DataInicial = driver.find_element_by_id('dataInicialApresentacao')\n",
    "    DataFinal = driver.find_element_by_id('dataFinalApresentacao')\n",
    "    # Preenche os campos de data\n",
    "    DataInicial.send_keys(data_inicial)\n",
    "    DataFinal.send_keys(data_final)\n",
    "    \n",
    "    #time.sleep(3)\n",
    "    # Encontra e clica no checkbox inteiro teor\n",
    "    inteiroteor = driver.find_element_by_id('inteiroteor')\n",
    "    inteiroteor.click()\n",
    "    #time.sleep(2)\n",
    "    # Encontra o local do input de palavras chaves e escreve a palavra\n",
    "    input_palavra_chave = driver.find_element_by_id('todasaspalavras')\n",
    "    input_palavra_chave.send_keys(chaves[0])\n",
    "    #time.sleep(2)\n",
    "    # Encontra e aperta o botão de pesquisar\n",
    "    submit_butt = driver.find_element_by_id('pesquisar')\n",
    "    submit_butt.click()\n",
    "    ## ------ fim pesquisa avançada ------------\n",
    "    ## ------ início do scraping das informações ---------- \n",
    "    PLs = []\n",
    "    Autores = []\n",
    "    Datas = []\n",
    "    # Passa por todas páginas e salva as informações importantes (Proposição, Autor e data de apresentação)\n",
    "    while True:\n",
    "        numeros_PL = driver.find_elements_by_class_name('titulo')\n",
    "        for PL in numeros_PL:\n",
    "            nome = PL.find_element_by_tag_name('span')\n",
    "            PLs.append(nome.get_attribute(\"innerHTML\"))\n",
    "\n",
    "        autor_PL = driver.find_elements_by_class_name('autor')\n",
    "        for autor in autor_PL:\n",
    "            nome = autor.find_element_by_tag_name('span')\n",
    "            Autores.append(nome.get_attribute(\"innerHTML\"))\n",
    "\n",
    "        data_PL = driver.find_elements_by_class_name('dataApres')\n",
    "        for data in data_PL:\n",
    "            nome = data.find_element_by_tag_name('span')\n",
    "            nome = nome.find_element_by_tag_name('span')\n",
    "            Datas.append(nome.get_attribute(\"innerHTML\").replace('&nbsp;',''))\n",
    "\n",
    "        resultado = driver.find_element_by_id('msgQtdResultados')\n",
    "        resultado = resultado.find_elements_by_tag_name('strong')\n",
    "\n",
    "        final = resultado[2].get_attribute(\"innerHTML\")\n",
    "        ref = resultado[1].get_attribute(\"innerHTML\")\n",
    "        print(ref)\n",
    "        if final == ref:\n",
    "            break\n",
    "\n",
    "        next_button = driver.find_element_by_link_text('Próxima')\n",
    "        next_button.click()\n",
    "        ## ------ fim do scraping das informações ---------- \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    # Fecha o google crhome\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva informações em um excel\n",
    "infos = pd.DataFrame({'PL':PLs,'Autor':Autores, 'Data':Datas})\n",
    "infos.drop_duplicates().to_excel('saude_publica.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raspando informações - Chave: Sistema Único de Saúde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20:1610\n",
      "40:1610\n",
      "60:1610\n",
      "80:1610\n",
      "100:1610\n",
      "100:1610\n",
      "100:1610\n",
      "100:1610\n",
      "100:1610\n",
      "100:1610\n",
      "120:1610\n",
      "140:1610\n",
      "160:1610\n",
      "180:1610\n",
      "200:1610\n",
      "220:1610\n",
      "240:1610\n",
      "260:1610\n",
      "280:1610\n",
      "300:1610\n",
      "320:1610\n",
      "340:1610\n",
      "360:1610\n",
      "380:1610\n",
      "400:1610\n",
      "420:1610\n",
      "440:1610\n",
      "460:1610\n",
      "480:1610\n",
      "500:1610\n",
      "520:1610\n",
      "540:1610\n",
      "560:1610\n",
      "580:1610\n",
      "600:1610\n",
      "620:1610\n",
      "640:1610\n",
      "660:1610\n",
      "680:1610\n",
      "700:1610\n",
      "720:1610\n",
      "740:1610\n",
      "760:1610\n",
      "780:1610\n",
      "800:1610\n",
      "820:1610\n",
      "840:1610\n",
      "860:1610\n",
      "880:1610\n",
      "900:1610\n",
      "920:1610\n",
      "940:1610\n",
      "960:1610\n",
      "980:1610\n",
      "1000:1610\n",
      "1020:1610\n",
      "1040:1610\n",
      "1060:1610\n",
      "1080:1610\n",
      "1100:1610\n",
      "1120:1610\n",
      "1140:1610\n",
      "1160:1610\n",
      "1180:1610\n",
      "1200:1610\n",
      "1220:1610\n",
      "1240:1610\n",
      "1260:1610\n",
      "1280:1610\n",
      "1300:1610\n",
      "1320:1610\n",
      "1340:1610\n",
      "1360:1610\n",
      "1380:1610\n",
      "1400:1610\n",
      "1420:1610\n",
      "1440:1610\n",
      "1460:1610\n",
      "1480:1610\n",
      "1500:1610\n",
      "1520:1610\n",
      "1540:1610\n",
      "1560:1610\n",
      "1580:1610\n",
      "1600:1610\n",
      "1610:1610\n"
     ]
    }
   ],
   "source": [
    "# Abre o google crhome\n",
    "driver = webdriver.Chrome()\n",
    "try:\n",
    "    driver.get('https://www.camara.leg.br/buscaProposicoesWeb/pesquisaAvancada')\n",
    "    ## ------ início pesquisa avançada ------------\n",
    "    # Aperta oos botões baseado no ID deles\n",
    "    for bot in botoes:\n",
    "        botao = driver.find_element_by_id(bot)\n",
    "        botao.click()\n",
    "    # Seleciona a checkbox sim para Em Tramitação\n",
    "    is_tram_yes = driver.find_element_by_xpath('/html/body/div[1]/div[2]/div/div/div/div[2]/div/div/div/div/form/fieldset[2]/fieldset/ul/li[2]/input')\n",
    "    is_tram_yes.click()\n",
    "    \n",
    "    #time.sleep(2)\n",
    "    # Encontra os campos de datas\n",
    "    DataInicial = driver.find_element_by_id('dataInicialApresentacao')\n",
    "    DataFinal = driver.find_element_by_id('dataFinalApresentacao')\n",
    "    # Preenche os campos de data\n",
    "    DataInicial.send_keys(data_inicial)\n",
    "    DataFinal.send_keys(data_final)\n",
    "    \n",
    "    #time.sleep(3)\n",
    "    # Encontra e clica no checkbox inteiro teor\n",
    "    inteiroteor = driver.find_element_by_id('inteiroteor')\n",
    "    inteiroteor.click()\n",
    "    #time.sleep(2)\n",
    "    # Encontra o local do input de palavras chaves e escreve a palavra\n",
    "    input_palavra_chave = driver.find_element_by_id('todasaspalavras')\n",
    "    input_palavra_chave.send_keys(chaves[1])\n",
    "    #time.sleep(2)\n",
    "    # Encontra e aperta o botão de pesquisar\n",
    "    submit_butt = driver.find_element_by_id('pesquisar')\n",
    "    submit_butt.click()\n",
    "    ## ------ fim pesquisa avançada ------------\n",
    "    ## ------ início do scraping das informações ---------- \n",
    "    PLs = []\n",
    "    Autores = []\n",
    "    Datas = []\n",
    "    # Passa por todas páginas e salva as informações importantes (Proposição, Autor e data de apresentação)\n",
    "    while True:\n",
    "        numeros_PL = driver.find_elements_by_class_name('titulo')\n",
    "        for PL in numeros_PL:\n",
    "            nome = PL.find_element_by_tag_name('span')\n",
    "            PLs.append(nome.get_attribute(\"innerHTML\"))\n",
    "\n",
    "        autor_PL = driver.find_elements_by_class_name('autor')\n",
    "        for autor in autor_PL:\n",
    "            nome = autor.find_element_by_tag_name('span')\n",
    "            Autores.append(nome.get_attribute(\"innerHTML\"))\n",
    "\n",
    "        data_PL = driver.find_elements_by_class_name('dataApres')\n",
    "        for data in data_PL:\n",
    "            nome = data.find_element_by_tag_name('span')\n",
    "            nome = nome.find_element_by_tag_name('span')\n",
    "            Datas.append(nome.get_attribute(\"innerHTML\").replace('&nbsp;',''))\n",
    "        \n",
    "        # Encontra quantas proposições já foram baixadas e quantas faltam\n",
    "        resultado = driver.find_element_by_id('msgQtdResultados')\n",
    "        resultado = resultado.find_elements_by_tag_name('strong')\n",
    "        final = resultado[2].get_attribute(\"innerHTML\")\n",
    "        ref = resultado[1].get_attribute(\"innerHTML\")\n",
    "        \n",
    "        print(f'{ref}:{final}')\n",
    "        # Checa se está na última página, caso sim, termina o código\n",
    "        if final == ref:\n",
    "            break\n",
    "        \n",
    "        # Clica no botão de Next\n",
    "        next_button = driver.find_element_by_link_text('Próxima')\n",
    "        next_button.click()\n",
    "        ## ------ fim do scraping das informações ---------- \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "finally:\n",
    "    # Fecha o google crhome\n",
    "    driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salva informações em um excel\n",
    "infos2 = pd.DataFrame({'PL':PLs2,'Autor':Autores2, 'Data':Datas2})\n",
    "infos2.drop_duplicates().to_excel('SUS.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
